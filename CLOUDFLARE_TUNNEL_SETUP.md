# Gu√≠a de Configuraci√≥n de Cloudflare Tunnel para Ollama

Esta gu√≠a te ayudar√° a configurar Cloudflare Tunnel para exponer Ollama de forma segura desde tu PC.

## üìã Requisitos Previos

- Ollama instalado y funcionando en tu PC
- Cuenta de Cloudflare (gratis)
- Windows 10/11

## üöÄ Paso 1: Instalar Cloudflare Tunnel

### Opci√≥n A: Con winget (Recomendado)

```powershell
winget install --id Cloudflare.cloudflared
```

### Opci√≥n B: Descarga Manual

1. Ve a: https://github.com/cloudflare/cloudflared/releases
2. Descarga `cloudflared-windows-amd64.exe`
3. Ren√≥mbralo a `cloudflared.exe`
4. Col√≥calo en una carpeta que est√© en tu PATH (ej: `C:\Windows\System32\`)

## üîê Paso 2: Autenticarse con Cloudflare

Abre PowerShell como administrador y ejecuta:

```powershell
cloudflared tunnel login
```

Esto abrir√° tu navegador para autenticarte. Si no ten√©s cuenta, creala (es gratis).

## üèóÔ∏è Paso 3: Crear el T√∫nel

```powershell
cloudflared tunnel create ollama-tunnel
```

**IMPORTANTE:** Guard√° el ID del t√∫nel que te muestra (algo como `abc-123-def-456`).

## ‚öôÔ∏è Paso 4: Configurar el T√∫nel

1. Crear la carpeta: `C:\Users\[TU-USUARIO]\.cloudflared\`
2. Crear el archivo: `C:\Users\[TU-USUARIO]\.cloudflared\config.yml`

**Contenido del archivo `config.yml`:**

```yaml
tunnel: ollama-tunnel
credentials-file: C:\Users\[TU-USUARIO]\.cloudflared\[TU-TUNNEL-ID].json

ingress:
  - service: http://localhost:11434
```

**Reemplaz√°:**
- `[TU-USUARIO]` con tu nombre de usuario de Windows
- `[TU-TUNNEL-ID]` con el ID del t√∫nel que obtuviste en el paso 3

**Ejemplo real:**
```yaml
tunnel: ollama-tunnel
credentials-file: C:\Users\User\.cloudflared\abc-123-def-456.json

ingress:
  - service: http://localhost:11434
```

## ‚ñ∂Ô∏è Paso 5: Ejecutar el T√∫nel

```powershell
cloudflared tunnel run ollama-tunnel
```

Ver√°s algo como:

```
+----------------------------------------------------------------------------+
|  Your quick Tunnel has been created! Visit it at (it may take some time   |
|  to be reachable):                                                         |
|  https://abc-123-def-456.cfargotunnel.com                                  |
+----------------------------------------------------------------------------+
```

**Copi√° esa URL** (ej: `https://abc-123-def-456.cfargotunnel.com`)

## üîß Paso 6: Configurar en Vercel

1. Ve a tu proyecto en [Vercel Dashboard](https://vercel.com/dashboard)
2. Ve a **Settings** ‚Üí **Environment Variables**
3. Agrega una nueva variable:
   - **Name:** `OLLAMA_URL`
   - **Value:** `https://abc-123-def-456.cfargotunnel.com` (la URL que copiaste)
   - **Environments:** Marca todas (Production, Preview, Development)
4. Haz clic en **Save**
5. Ve a **Deployments** y haz un nuevo deploy (o espera al pr√≥ximo push)

## ‚úÖ Paso 7: Verificar

1. Asegurate de que Ollama est√© corriendo:
   ```powershell
   ollama serve
   ```

2. Asegurate de que el t√∫nel est√© corriendo:
   ```powershell
   cloudflared tunnel run ollama-tunnel
   ```

3. En tu app de Vercel, ve al chat de stock
4. Deber√≠a mostrar "Ollama conectado" ‚úÖ

## üéØ Para la Presentaci√≥n

Antes de la presentaci√≥n, ejecut√° el script `iniciar-ollama-tunnel.bat` que est√° en la ra√≠z del proyecto.

O manualmente:

1. Abr√≠ una terminal y ejecut√°:
   ```powershell
   ollama serve
   ```

2. Abr√≠ otra terminal y ejecut√°:
   ```powershell
   cloudflared tunnel run ollama-tunnel
   ```

3. Dej√° ambas ventanas abiertas durante la presentaci√≥n

## üîç Verificar que Ollama Funciona

```powershell
# Ver modelos disponibles
ollama list

# Si no ten√©s modelos, descargar uno:
ollama pull llama3.2
```

## üõ†Ô∏è Soluci√≥n de Problemas

### El t√∫nel no se conecta

1. Verific√° que Ollama est√© corriendo en `http://localhost:11434`
2. Verific√° que el archivo `config.yml` est√© en la ubicaci√≥n correcta
3. Verific√° que el ID del t√∫nel en `config.yml` sea correcto

### La URL del t√∫nel cambia

- Las URLs de Cloudflare Tunnel son estables, pero si cambiaste algo, verific√° la nueva URL ejecutando:
  ```powershell
  cloudflared tunnel run ollama-tunnel
  ```

### Ollama no responde

1. Verific√° que Ollama est√© corriendo:
   ```powershell
   curl http://localhost:11434/api/tags
   ```

2. Verific√° que tengas modelos descargados:
   ```powershell
   ollama list
   ```

## üìù Notas Importantes

- **La URL del t√∫nel es p√∫blica** pero oculta tu IP real
- **No necesit√°s abrir puertos** en tu router
- **El t√∫nel debe estar corriendo** cuando quieras usar Ollama desde Vercel
- **Ollama debe estar corriendo** en tu PC para que funcione

## üîí Seguridad

Para una presentaci√≥n est√° bien, pero para producci√≥n considera:
- Agregar autenticaci√≥n al proxy
- Usar un servicio en la nube (Railway, Render, etc.)
- Limitar el acceso por IP (si es posible)

