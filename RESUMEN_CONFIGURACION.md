# ‚úÖ Resumen de Configuraci√≥n - Cloudflare Tunnel

## ‚úÖ Lo que ya est√° hecho:

1. ‚úÖ **Autenticaci√≥n con Cloudflare** - Completada
2. ‚úÖ **T√∫nel creado** - `ollama-tunnel` con ID: `7b97f006-14c1-46d5-b57e-f378e3a39ba2`
3. ‚úÖ **Archivo de configuraci√≥n creado** - `C:\Users\User\.cloudflared\config.yml`

## üìã Pasos finales (hacer manualmente):

### 1. Asegurarse de que Ollama est√© corriendo

Abre PowerShell y ejecuta:

```powershell
ollama serve
```

O verifica que est√© corriendo:

```powershell
ollama list
```

### 2. Ejecutar el t√∫nel de Cloudflare

En otra ventana de PowerShell, ejecuta:

```powershell
cloudflared tunnel run ollama-tunnel
```

**IMPORTANTE:** Ver√°s una URL como:
```
https://abc-123-def-456.cfargotunnel.com
```

**¬°COPIA ESA URL!** Es la que necesit√°s para Vercel.

### 3. Configurar en Vercel

1. Ve a [Vercel Dashboard](https://vercel.com/dashboard)
2. Selecciona tu proyecto
3. Ve a **Settings** ‚Üí **Environment Variables**
4. Agrega nueva variable:
   - **Name:** `OLLAMA_URL`
   - **Value:** `https://[la-url-que-copiaste].cfargotunnel.com`
   - **Environments:** ‚úÖ Production, ‚úÖ Preview, ‚úÖ Development
5. Haz clic en **Save**
6. Ve a **Deployments** y haz un nuevo deploy

### 4. Verificar que funcione

1. En tu app de Vercel, ve al chat de stock
2. Deber√≠a mostrar "Ollama conectado" ‚úÖ

## üéØ Para la Presentaci√≥n

Antes de la presentaci√≥n:

1. **Inicia Ollama:**
   ```powershell
   ollama serve
   ```

2. **Inicia el t√∫nel:**
   ```powershell
   cloudflared tunnel run ollama-tunnel
   ```

3. **Deja ambas ventanas abiertas** durante la presentaci√≥n

## üîç Verificar Modelos

Si no ten√©s modelos descargados:

```powershell
ollama pull llama3.2
```

## üìù Notas

- El t√∫nel debe estar corriendo cuando quieras usar Ollama desde Vercel
- La URL del t√∫nel es estable (no cambia a menos que elimines el t√∫nel)
- Tu IP real est√° oculta gracias al t√∫nel
- No necesit√°s abrir puertos en tu router

## üÜò Soluci√≥n de Problemas

### El t√∫nel no se conecta
- Verifica que Ollama est√© corriendo: `ollama list`
- Verifica que el archivo `config.yml` est√© en `C:\Users\User\.cloudflared\`

### cloudflared no se encuentra
- Si lo instalaste con winget, puede estar en: `C:\Users\User\AppData\Local\Microsoft\WinGet\Packages\`
- O ejecuta: `winget install --id Cloudflare.cloudflared`

### Ollama no responde
- Verifica que est√© corriendo: `curl http://localhost:11434/api/tags`
- Reinicia Ollama: Cierra la ventana y ejecuta `ollama serve` de nuevo

